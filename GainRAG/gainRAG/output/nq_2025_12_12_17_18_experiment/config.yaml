model2path:
    e5: /root/siton-data-0553377b2d664236bad5b5d0ba8aa419/workspace/FlashRAG/models/e5-base-v2
    bge: BAAI/bge-base-en-v1.5
    contriever: facebook/contriever
    llama2-7B-chat: meta-llama/Llama-2-7b-chat-hf
    llama2-7B: meta-llama/Llama-2-7b-hf
    llama2-13B: meta-llama/Llama-2-13b-hf
    llama2-13B-chat: meta-llama/Llama-2-13b-chat-hf
    llama3-8B-instruct: /root/siton-data-0553377b2d664236bad5b5d0ba8aa419/workspace/FlashRAG/models/Meta-Llama-3-8B-Instruct
model2pooling:
    e5: mean
    bge: cls
    contriever: mean
    jina: mean
    dpr: cls
method2index:
    e5: null
    bm25: null
    contriever: null
    clip:
        text: path/to/text_index
        image: path/to/image_index
data_dir: /root/siton-data-0553377b2d664236bad5b5d0ba8aa419/workspace/FlashRAG/FlashRAG_Dataset
save_dir: output/nq_2025_12_12_17_18_experiment
gpu_id: 0
dataset_name: nq
split:
- test
- dev
test_sample_num: 500
random_sample: false
seed: 2024
save_intermediate_data: true
save_note: experiment
retrieval_method: /root/siton-data-0553377b2d664236bad5b5d0ba8aa419/workspace/FlashRAG/models/e5-base-v2
retrieval_model_path: /root/siton-data-0553377b2d664236bad5b5d0ba8aa419/workspace/FlashRAG/models/e5-base-v2
index_path: /root/siton-data-0553377b2d664236bad5b5d0ba8aa419/workspace/FlashRAG/FlashRAG_Dataset/retrieval_corpus/data00/jiajie_jin/flashrag_indexes/wiki_dpr_100w/e5_flat_inner.index
multimodal_index_path_dict: null
faiss_gpu: false
corpus_path: /root/siton-data-0553377b2d664236bad5b5d0ba8aa419/workspace/FlashRAG/FlashRAG_Dataset/retrieval_corpus/wiki18_100w.jsonl
instruction: null
retrieval_topk: 20
retrieval_batch_size: 256
retrieval_use_fp16: true
retrieval_query_max_length: 128
save_retrieval_cache: true
use_retrieval_cache: false
retrieval_cache_path: null
retrieval_pooling_method: mean
bm25_backend: bm25s
use_sentence_transformer: false
silent_retrieval: true
use_reranker: true
rerank_model_name: bge-reranker-base
rerank_model_path: ./model_outputs/test_grpo_new_sample/
rerank_pooling_method: cls
rerank_topk: 5
rerank_max_length: 512
rerank_batch_size: 128
rerank_use_fp16: true
use_multi_retriever: false
multi_retriever_setting:
    merge_method: concat
    topk: 5
    rerank_model_name: null
    rerank_model_path: null
    retriever_list:
    -   retrieval_method: e5
        retrieval_topk: 5
        index_path: null
        retrieval_model_path: /root/siton-data-0553377b2d664236bad5b5d0ba8aa419/workspace/FlashRAG/models/e5-base-v2
        instruction: null
        bm25_backend: bm25s
        use_reranker: false
        corpus_path: null
        use_sentence_transformer: false
        retrieval_pooling_method: mean
        retrieval_use_fp16: true
        retrieval_query_max_length: 128
        faiss_gpu: false
        retrieval_batch_size: 256
        rerank_model_name: bge-reranker-base
        rerank_model_path: ./model_outputs/test_grpo_new_sample/
        retrieval_cache_path: null
        save_retrieval_cache: false
        use_retrieval_cache: false
    -   retrieval_method: bm25
        retrieval_topk: 5
        index_path: null
        retrieval_model_path: bm25
        instruction: null
        bm25_backend: bm25s
        use_reranker: false
        corpus_path: null
        use_sentence_transformer: false
        retrieval_pooling_method: mean
        retrieval_use_fp16: true
        retrieval_query_max_length: 128
        faiss_gpu: false
        retrieval_batch_size: 256
        rerank_model_name: bge-reranker-base
        rerank_model_path: ./model_outputs/test_grpo_new_sample/
        retrieval_cache_path: null
        save_retrieval_cache: false
        use_retrieval_cache: false
framework: hf
generator_model: llama3-8B-instruct
openai_setting:
    api_key: sk-xxx
    base_url: https://xxx.xxx.xxx
generator_model_path: /root/siton-data-0553377b2d664236bad5b5d0ba8aa419/workspace/FlashRAG/models/Meta-Llama-3-8B-Instruct
generator_max_input_len: 1024
generator_batch_size: 4
generation_params:
    max_tokens: 512
use_fid: false
gpu_memory_utilization: 0.85
metrics:
- em
- f1
- acc
- retrieval_recall
metric_setting:
    retrieval_recall_topk: 5
    tokenizer_name: gpt-4
save_metric_score: true
dataset_path: /root/siton-data-0553377b2d664236bad5b5d0ba8aa419/workspace/FlashRAG/FlashRAG_Dataset/nq
gpu_num: 1
device: cuda

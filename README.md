<div align="center">

# GainRAG: Preference Alignment in Retrieval-Augmented Generation through Gain Signal Synthesis 

<p align="center">

  <a href="https://arxiv.org/abs/2505.18710">
    <img src="https://img.shields.io/badge/arXiv-2505.18710-b31b1b.svg" alt="arXiv">
  </a>
</p>
</div>


<div align="center">
<img src="images/framework.png" alt="framework" width="800">

**GainRAG Framework**
</div>

## ðŸ›  Installation


<details>
<summary>
The main dependencies are torch 2.5.1, vllm 0.7.3, FlagEmbedding 1.3.3, DeepSpeed, trl, peft, faiss/faiss-gpu.
</summary>

```bash
conda create -n GainRAG python=3.9.18
conda activate GainRAG
pip install -r requirements.txt
```
</details>


## ðŸ’¡ Preparation
***Download Corpus & Index***

<details>
<summary>
Retrieval is performed on the set of Wikipeda passages used in DPR. Download passages:
</summary>

```bash
wget https://dl.fbaipublicfiles.com/dpr/wikipedia_split/psgs_w100.tsv.gz
```
</details>

<details>
<summary>
Download passage embeddings pre-computed with Contriever or Contriever-msmarco:
</summary>
    
```bash
wget https://dl.fbaipublicfiles.com/contriever/embeddings/contriever/wikipedia_embeddings.tar
wget https://dl.fbaipublicfiles.com/contriever/embeddings/contriever-msmarco/wikipedia_embeddings.tar
```
</details>

<details>
<summary>
Retrieve top-k passages:
</summary>
  
```bash
cd ./gainRAG/retrieval_engine
python retrieval.py # Remember to configure your parameters
```
</details>


## ðŸŽ¯ Train Selector
<details>
<summary>
Gain Signal Synthesis:
</summary>
  
```bash
cd ./gainRAG
python -m llm_supervision.construct_hf \
    --data_path  TODOpath/data.jsonl \
    --output_path  TODOpath/data_train.json \
    --task HotpotQA \
    --alpha 0.5
```
</details>

<details>
<summary>
Data format conversion:
</summary>
  
```bash
cd ./data
python data2selector.py # Remember to configure your parameters
```
</details>

<details>
<summary>
Selector Training:
</summary>

The initial weight of the model is bge-rerank-baseï¼Œ
```bash
cd ./gainRAG
torchrun --nproc_per_node 1 -m selector_finetune --model_name_or_path  /root/.cache/huggingface/hub/models--BAAI--bge-reranker-base/snapshots/2cfc18c9415c912f9d8155881c133215df768a70     --train_data /root/siton-data-0553377b2d664236bad5b5d0ba8aa419/workspace/GainRAG/GainRAG/data/without_pse_nq_train_selector_sampled_13971.jsonl  --output_dir ./model_outputs/test_grpo2/--overwrite_output_dir     --train_group_size 16 --knowledge_distillation True     --query_max_len 256     --passage_max_len 256 --max_len 512    --pad_to_multiple_of 8     --learning_rate 6e-5     --fp16     --num_train_epochs 2     --per_device_train_batch_size 8     --gradient_accumulation_steps 1     --dataloader_drop_last True     --warmup_ratio 0.1     --gradient_checkpointing     --weight_decay 0.01     --logging_steps 1     --save_steps 5000
```
</details>

## ðŸ“ˆ Run Evaluation
<details>
<summary>
0. Download Evaluation Data:
</summary>
  
[HotpotQA](https://hotpotqa.github.io/), [2WikiMultiHopQA](https://github.com/Alab-NII/2wikimultihop), [WebQuestions](https://nlp.stanford.edu/software/sempre/), [NaturalQA](https://ai.google.com/research/NaturalQuestions), [TriviaQA](http://nlp.cs.washington.edu/triviaqa/), [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)
</details>


<details>
<summary>
1. Retrieve top-k passages:
</summary>
  
```bash
cd ./gainRAG/retrieval_engine
python retrieval.py # Remember to configure your parameters
```
</details>

<details>
<summary>
2. Select top-1 passages:
</summary>
  
```bash
cd ./gainRAG
python -m selector_engine.selector_gainRag \
    --model_name_or_path "model_path/" \
    --data_path "path/GainRAG/data/eval_data/HotpotQA.jsonl" \
    --output_path "path/GainRAG/data/test.json" \
    --K_docs 1
```
</details>

<details>
<summary>
3. Run generation & evaluation:
</summary>
  
```bash
cd ./gainRAG
python -m rag_workflow.rag_generation \
    --data_path "selector_output_path" \
    --task "HotpotQA" \
    --lm_type "Llama-3-8B-Instruct" \
    --K_docs 1
```
</details>


## Citation
```bibtex
@article{jiang2025gainrag,
  title={GainRAG: Preference Alignment in Retrieval-Augmented Generation through Gain Signal Synthesis},
  author={Jiang, Yi and Zhao, Sendong and Li, Jianbo and Wang, Haochun and Qin, Bing},
  journal={arXiv preprint arXiv:2505.18710},
  year={2025}
}
```

Thanks for your interest in our work!




